{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def connectivity(data):\n",
    "    '''Compute Pearson correlation for every patient'''\n",
    "    ## data - nTime x nChannels x nPatients\n",
    "    if data.ndim == 1:\n",
    "        connMatrix = -1\n",
    "    elif data.ndim == 2:\n",
    "        connMatrix = np.corrcoef(data.T)\n",
    "    else:\n",
    "        connMatrix = np.zeros((np.size(data,2),np.size(data,1),np.size(data,1)))\n",
    "        for i in range(np.size(data,2)):\n",
    "            dataTmp = data[:,:,i]\n",
    "            connMatrix[i] = np.corrcoef(dataTmp.T)\n",
    "    return connMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def orderMatrix(connMatrix):\n",
    "#     #values sorted max to min, as usual in correlation business; \n",
    "#     var = -connMatrix \n",
    "#     corr_mat = np.zeros(np.shape(var))\n",
    "#     sorted_num = np.sort(np.unique(var[var!=0]))\n",
    "#     for count in range(0,len(sorted_num)):\n",
    "#         var[np.where(var==sorted_num[count])]=count+1\n",
    "#         corr_mat[:,:]=var\n",
    "#     return corr_mat\n",
    "\n",
    "import numpy as np\n",
    "def orderMatrix_single(connMatrix):\n",
    "    '''Turn matrix it its ordered version. Diagonal 0'''\n",
    "    var = connMatrix # values sorted min to max. Be carful, for correlation sort max to min (BY HAND), as usual in correlation business; \n",
    "    N = np.size(var,0)\n",
    "    values = var[np.triu_indices(N,1)] # symmetric matrix to vector of upper triangle values\n",
    "    order = vectorOrder(values)+1 # from values to order\n",
    "    upMatr = createTriMatr_upper(order,N,1) # back to upper triangular matrix (diagonal 0)\n",
    "    ordMatrix = upMatr + upMatr.T # create symmetric matrix\n",
    "    return ordMatrix\n",
    "\n",
    "\n",
    "def orderMatrix(connMatrix):\n",
    "    '''Find order matrix for every patient'''\n",
    "    ## connMatrix - nChannels x nChannels x nPatients\n",
    "    ordMatrix = np.zeros(np.shape(connMatrix))\n",
    "    if ordMatrix.ndim == 2:\n",
    "        ordMatrix = orderMatrix_single(connMatrix)\n",
    "    else: \n",
    "        for i in range(np.size(connMatrix,0)):\n",
    "            ordMatrix[i] = orderMatrix_single(connMatrix[i])\n",
    "    return ordMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def shuffleMatrix_single(N):\n",
    "    '''Create symmetric random matrix NxN with uniform distribution'''\n",
    "    rand_vect = (np.random.permutation(binom(N)))\n",
    "    rand_mat = createTriMatr_upper(rand_vect,N,1)\n",
    "    rand_mat = rand_mat + rand_mat.T\n",
    "    return rand_mat\n",
    "\n",
    "\n",
    "def shuffleMatrix(N,K=0):\n",
    "    '''Radnom matrix for every patient'''\n",
    "    ## output matrix - N (Channels) x N (Channels) x K (Patients)\n",
    "    if K == 0:\n",
    "        ordMatrix = shuffleMatrix_single(N)\n",
    "    else: \n",
    "        ordMatrix = np.zeros((K,N,N))\n",
    "        for i in range(K):\n",
    "            ordMatrix[i] = shuffleMatrix_single(N)\n",
    "    return ordMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def randCorrMatrix(N, K = 1, Len = 400):\n",
    "    '''Radnom correlation matrix for every patient'''\n",
    "    ## output matrix - K (Patients) x N (Channels) x N (Channels)\n",
    "    ts = np.random.normal(size=(Len,N,K))\n",
    "    randCorrMatrix = connectivity(ts)\n",
    "    return randCorrMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def euclDistMatrix_single(N_sample, dim_space = 400):\n",
    "    geom_mat = np.zeros((N_sample,N_sample))\n",
    "    point_sample = np.random.uniform(low = 0, high = 1, size = (N_sample,dim_space))\n",
    "    for s in range(0,N_sample):\n",
    "        for t in range(s+1,N_sample):\n",
    "            geom_mat[s,t] = distance.euclidean(point_sample[s],point_sample[t])\n",
    "            geom_mat[t,s] = geom_mat[s,t]\n",
    "    # var = geom_mat\n",
    "    # sorted_num=np.sort(np.unique(var[var>0]))\n",
    "    # for count in range(0,binom(N_sample)):\n",
    "    #     var[np.where(var==sorted_num[count])]=count+1\n",
    "    #     geom_mat = var\n",
    "    return geom_mat\n",
    "    \n",
    "def euclDistMatrix(N, K = 0, dim_space = 400):\n",
    "    '''euclidean distance matrix for every patient'''\n",
    "    ## output matrix - K (Patients) x N (Channels) x N (Channels)\n",
    "    if K == 0:\n",
    "        outMatrix = euclDistMatrix_single(N,dim_space)\n",
    "    else: \n",
    "        outMatrix = np.zeros((K,N,N))\n",
    "        for i in range(K):\n",
    "            outMatrix[i] = euclDistMatrix_single(N,dim_space)\n",
    "    return outMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def hyperToEucl(hypPoints):\n",
    "    '''Function from [0,R] in hyperbolic geometry to [0,L<1] in euclidean'''\n",
    "    eucl = (np.cosh(hypPoints) - 1)/(2 + np.cosh(hypPoints))\n",
    "    return eucl\n",
    "    \n",
    "def hyperDensity(r, R = 10):\n",
    "    '''Compute hyperbolic density for radius r (max R)'''\n",
    "    rho = (np.exp(r)-np.exp(-r))/(np.exp(R)-np.exp(-R))\n",
    "    return rho\n",
    "\n",
    "def sampleHyperDistr(N_sample = 1000, R = 10):\n",
    "    '''Generate uniform distribution on [0,R] with hyp.distance'''\n",
    "    u = np.random.uniform(0,R,np.int(np.ceil(N_sample*(R+2)))) # generate uniformly more points than we need\n",
    "    rho = hyperDensity(u,R)  # compute hyperbolic density for them\n",
    "    remove_probability = np.random.uniform(0,hyperToEucl(R),size = np.size(u))  # probability, used to remove points\n",
    "    selPoints = u[remove_probability<rho]   # leave only rho percent of points\n",
    "    indices = np.random.randint(1,np.size(selPoints),N_sample) # select exact number of points\n",
    "    selPoints = selPoints[indices]\n",
    "    return selPoints\n",
    "\n",
    "    \n",
    "def distribution_on_disk(type = 'UniOnHyper', N_sample = 400, R = 10, expScale = 1):\n",
    "  if (type == 'Circle'):\n",
    "    print(type)\n",
    "    u = np.random.uniform(0.9999,1,N_sample)\n",
    "  elif (type == 'Disk'):\n",
    "    print(type)\n",
    "    u = np.random.uniform(0,1,N_sample)\n",
    "  elif (type == 'Expo'):\n",
    "    print(type)\n",
    "    u = np.random.exponential(scale = expScale, size = (1,N_sample))\n",
    "    u[u>=1] = 0.99999999\n",
    "    u = 1-u\n",
    "    # u = u*np.exp(-R)\n",
    "    print(np.max(u))\n",
    "  elif 'UniOnHyper':\n",
    "    hypPoints = sampleHyperDistr(N_sample,R)\n",
    "    euclPoints = hyperToEucl(hypPoints)\n",
    "    # euclPoints = hypPoints\n",
    "    u = euclPoints\n",
    "  else:\n",
    "    u = np.random.uniform(0,1,N_sample)\n",
    "  return u\n",
    "\n",
    "\n",
    "def distance_hyper(x, n_sample):\n",
    "    \" X should be normalized (norm <1) \"\n",
    "    geom_mat = np.zeros((n_sample, n_sample))\n",
    "    for s in range(0, n_sample):\n",
    "        for t in range(s + 1, n_sample):\n",
    "            norm_diff = np.power(np.linalg.norm(x[s] - x[t]), 2)\n",
    "            norm_s = np.power(np.linalg.norm(x[s]), 2)\n",
    "            norm_t = np.power(np.linalg.norm(x[t]), 2)\n",
    "            delta_st = (2 * norm_diff) / ((1 - norm_s) * (1 - norm_t))\n",
    "            geom_mat[s, t] = math.acosh(1 + delta_st)\n",
    "            geom_mat[t, s] = geom_mat[s, t]\n",
    "    return geom_mat\n",
    "\n",
    "\n",
    "def hyperbDistMatrix_single(N_sample, dim_space=400, distrType = 'UniOnHyper', R = 10):\n",
    "\n",
    "    vec = np.random.normal(size = (dim_space,N_sample))\n",
    "    vec /= np.linalg.norm(vec, axis=0) #creates random points on the unit sphere\n",
    "\n",
    "    u = distribution_on_disk(distrType, N_sample, R)\n",
    "    # r = np.power(u,1/dim_space) #random radius\n",
    "    \n",
    "    X = u*vec #resulting random vectors\n",
    "    X = X.transpose()\n",
    "\n",
    "    geom_mat = distance_hyper(X,N_sample)\n",
    "    return geom_mat\n",
    "\n",
    "def hyperbDistMatrix(N, K = 0, dim_space = 400, distrType = 'UniOnHyper', R = 1):\n",
    "    '''hyperbolic distance matrix for every patient'''\n",
    "    ## output matrix - K (Patients) x N (Channels) x N (Channels)\n",
    "    if K == 0:\n",
    "        outMatrix = hyperbDistMatrix_single(N, dim_space, distrType, R)\n",
    "    else: \n",
    "        outMatrix = np.zeros((K,N,N))\n",
    "        for i in range(K):\n",
    "            outMatrix[i] = hyperbDistMatrix_single(N, dim_space, distrType, R)\n",
    "    return outMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def spherDistMatrix_single(N_sample, dim_space=400):\n",
    "    vec = np.random.normal(size=(dim_space,N_sample))\n",
    "    vec /= np.linalg.norm(vec, axis=0) #creates random points on the unit sphere\n",
    "    vec = vec.transpose()\n",
    "    geom_mat = np.zeros((N_sample,N_sample))\n",
    "\n",
    "    for s in range(0,N_sample):\n",
    "        for t in range(s+1,N_sample):\n",
    "            geom_mat[s,t] = np.arccos(np.dot(vec[s],vec[t]))\n",
    "            geom_mat[t,s] = geom_mat[s,t]\n",
    "    # var = geom_mat\n",
    "    # sorted_num = np.sort(np.unique(var[var!=0]))\n",
    "    # for count in range(0,binom(N_sample)):\n",
    "    #     var[np.where(var==sorted_num[count])] = count+1\n",
    "    #     geom_mat = var\n",
    "    return geom_mat\n",
    "\n",
    "def spherDistMatrix(N, K = 0, dim_space = 400):\n",
    "    '''spherical distance matrix for every patient'''\n",
    "    ## output matrix - K (Patients) x N (Channels) x N (Channels)\n",
    "    if K == 0:\n",
    "        outMatrix = spherDistMatrix_single(N,dim_space)\n",
    "    else: \n",
    "        outMatrix = np.zeros((K,N,N))\n",
    "        for i in range(K):\n",
    "            outMatrix[i] = spherDistMatrix_single(N,dim_space)\n",
    "    return outMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistent Homology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ripser import ripser\n",
    "from tqdm import tqdm\n",
    "\n",
    "def computeBettiNumbers_single(ordMatr, minDim=0, maxDim=2):\n",
    "    N_max = binom(np.size(ordMatr,0))\n",
    "    N_trial = 1\n",
    "    N_betti = {}\n",
    "    for dim in range(0,maxDim+1):\n",
    "        N_betti['Betti'+str(dim)+''] = {}\n",
    "    diagrams = ripser(ordMatr, maxdim = maxDim, distance_matrix = True)['dgms']\n",
    "    for dim in range(minDim,maxDim+1):\n",
    "        N_betti['Betti'+str(dim)+''] = []\n",
    "        betti = diagrams[dim]\n",
    "        for index in range(0,N_max+1):\n",
    "            wo = np.array(np.where((betti[:,0] <= index)&(betti[:,1]>=index)))\n",
    "            N_betti['Betti'+str(dim)+''].append(wo.shape[1])\n",
    "    return N_betti\n",
    "\n",
    "def computeBettiNumbers(ordMatr, minDim=0, maxDim=2):\n",
    "    N_max = binom(np.size(ordMatr,1))\n",
    "    if ordMatr.ndim == 2:\n",
    "        N_trial = 1\n",
    "    else:\n",
    "        N_trial = np.size(ordMatr,0)\n",
    "    N_betti = {}\n",
    "    N_betti_arr = {}\n",
    "    for dim in range(minDim,maxDim+1):\n",
    "        N_betti_arr['Betti'+str(dim)] = np.zeros((N_max+1,N_trial))\n",
    "    for m in tqdm(range(0,N_trial), desc=\"Loading...\"):\n",
    "        N_betti[m] = computeBettiNumbers_single(ordMatr[m], minDim, maxDim)\n",
    "        for dim in range(minDim,maxDim+1):\n",
    "            N_betti_arr['Betti'+str(dim)][:,m] = N_betti[m]['Betti'+str(dim)]\n",
    "    return N_betti_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def binom(num):\n",
    "    return int(math.factorial(num)/(2*math.factorial(num-2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "def vectorOrder(values):\n",
    "    order = (rankdata(values) - 1).astype(int)\n",
    "    if np.std(order)==0:\n",
    "        order = np.ones((np.size(order)))*np.min(values)\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def createTriMatr_upper(values, size, offDiag = 0):\n",
    "    upper = np.zeros((size, size))\n",
    "    upper[np.triu_indices(size, offDiag)] = values\n",
    "    return(upper)\n",
    "\n",
    "def createTriMatr_lower(values, size, offDiag = 0):\n",
    "    lower = np.zeros((size, size))\n",
    "    lower[np.tril_indices(size, offDiag)] = values\n",
    "    return(lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(N_betti,ma = 1):\n",
    "    N = np.size(N_betti['Betti0'],1)\n",
    "    x = np.zeros((3,N))\n",
    "    xs = np.zeros((2,1))\n",
    "    ys = np.zeros((2,1))\n",
    "    for i in range(N):\n",
    "        x[0,i] = np.sum(N_betti['Betti0'][:,i])/N_betti['Betti0'][1,i] #slope_no_time(N_betti['Betti0'][:,i])\n",
    "        x[1,i] = np.sum(N_betti['Betti1'][:,i])\n",
    "        x[2,i] = i\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(points_current):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x = points_current[0], \n",
    "        y = points_current[1],\n",
    "        z = points_current[2],\n",
    "        mode='markers', \n",
    "        showlegend=False,\n",
    "        marker={\n",
    "            'color': points_current[2], \n",
    "            'colorscale': 'Rainbow', \n",
    "            'cmax' : points_current[2].max(),\n",
    "            'showscale': True, \n",
    "            'colorbar' : dict(thickness=10)\n",
    "        }\n",
    "        ))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17797b2132b1940379b3c930a931435bb326cb4a1b41dad3fd91f0c229a028d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
